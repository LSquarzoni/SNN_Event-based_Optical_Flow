experiment: Default

data:
    path: /usr/scratch/badile13/amarchei/training/ # path to dataset in the server
    #path: /usr/scratch/badile13/amarchei/training_256x256/ # path to 256x256 dataset
    mode: events # events
    window: 1000 # events
    window_loss: 10000 # events

model:
    name: LIFFireNet # for other models available, see models/model.py
    #name: LIFFireNet_short # shorter model with 6 layers instead of 8
    #name: LIFFireFlowNet # no recurrent model
    #name: LIFFireFlowNet_short # no recurrent model with only 6 layers
    encoding: cnt # voxel/cnt
    round_encoding: False # for voxel encoding
    norm_input: False # normalize input
    num_bins: 2
    base_num_channels: 32
    kernel_size: 3
    activations: [arctanspike, arctanspike] # activations for ff and rec neurons
    mask_output: True
    quantization:
        enabled: True
        PTQ: False 
        Conv_only: False

spiking_neuron:
    leak: [0.0, 1.0]
    thresh: [0.0, 0.8]
    learn_leak: True
    learn_thresh: True
    hard_reset: True
    
loss:
    flow_regul_weight: 0.001
    clip_grad: 1.0 # set to Null to disable # was 100.0
    overwrite_intermediate: False

optimizer:
    #name: Adam
    #lr: 0.0002
    name: SGD
    lr: 0.0001  # Lower than Adam, start conservative
    momentum: 0.9
    weight_decay: 0.0001  # Small regularization helps stability
    nesterov: True  # Nesterov momentum is smoother

loader:
    n_epochs: 50
    batch_size: 4
    resolution: [128, 128] # H x W
    std_resolution: [128, 128] # H x W
    augment: ["Horizontal", "Vertical", "Polarity"]
    augment_prob: [0.5, 0.5, 0.5]
    gpu: 0

vis:
    verbose: True
    enabled: False
    px: 400
    store_grads: False

hot_filter:
    enabled: False
    max_px: 100
    min_obvs: 5
    max_rate: 0.8
