data:
    #path: ./datasets/MVSEC_h5/ # path for the dataset in my local machine
    path: /usr/scratch/badile13/amarchei/MVSEC_evflow/h5/
    mode: gtflow_dt1 # gtflow_dt1/gtflow_dt4
    window: 1 # 1 for dt1, 0.25 for dt4
    window_eval: 15000 # not used

model:
    exporting: False
    mask_output: True
    quantization:
        enabled: False
        PTQ: False # Post Training Quantization enabled or not
        Conv_only: False

# To generate non-trained models -----------------------------------------------------------
    #name: LIFFireNet # for other models available, see models/model.py
    #name: LIFFireNet_short # shorter model with 6 layers instead of 8
    #name: LIFFireFlowNet # no recurrent model
    #name: LIFFireFlowNet_short # no recurrent model with only 6 layers
    encoding: cnt # voxel/cnt
    round_encoding: False # for voxel encoding
    norm_input: False # normalize input
    num_bins: 2
    #base_num_channels: 32
    kernel_size: 3
    activations: [arctanspike, arctanspike] # activations for ff and rec neurons

    spiking_neuron:
        leak: [0.0, 1.0]
        thresh: [0.0, 0.8]
        learn_leak: True
        learn_thresh: True
        hard_reset: True
# ----------------------------------------------------------------------------------------

metrics:
    name: ["AEE", "AAE", "AE_ofMeans"]
    flow_scaling: 128
    heat_map: False

loader:
    batch_size: 1
    resolution: [64, 64] # H x W, if the resolution is smaller than the input one, frames and events will be cropped at the center
    std_resolution: [256, 256]
    augment: []
    gpu: 0


vis:
    enabled: False
    px: 400
    bars: True
    activity: False
    store: True
    store_interval: 0.0  # store every x seconds, 0.0 to disable
    #type: vectors # gradients or vectors
    store_type: video # video or image

hot_filter:
    enabled: True
    max_px: 100
    min_obvs: 5
    max_rate: 0.8
